{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as t\n",
    "import cv2\n",
    "import math\n",
    "import pyautogui as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Capturing video through front camera(webcam)\n",
    "cap=cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "#Window Name where we adjust the visibility of our hand\n",
    "cv2.namedWindow(\"Colour Adjustments\",cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Colour Adjustments\",(300,300))\n",
    "cv2.createTrackbar(\"Thresh\",\"Colour Adjustments\",0,255,nothing)\n",
    "\n",
    "#Create Colour Detection Track\n",
    "cv2.createTrackbar(\"Lower_H\",\"Colour Adjustments\",0,255,nothing)\n",
    "cv2.createTrackbar(\"Lower_S\",\"Colour Adjustments\",0,255,nothing)\n",
    "cv2.createTrackbar(\"Lower_V\",\"Colour Adjustments\",0,255,nothing)\n",
    "cv2.createTrackbar(\"Upper_H\",\"Colour Adjustments\",255,255,nothing)\n",
    "cv2.createTrackbar(\"Upper_S\",\"Colour Adjustments\",255,255,nothing)\n",
    "cv2.createTrackbar(\"Upper_V\",\"Colour Adjustments\",255,255,nothing)\n",
    "\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    frame=cv2.flip(frame,2)\n",
    "    frame=cv2.resize(frame,(500,400))\n",
    "    \n",
    "    #Creating the box where hand data is going to be read\n",
    "    frame=cv2.rectangle(frame,(0,1),(250,400),(255,0,0),0)\n",
    "    crop_image=frame[1:400,0:250]\n",
    "    #NOTE:After resizing the shape of our frame is (400,500,3) ie. 400 rows,500 columns and 3 channels. Now since we have to\n",
    "    #crop image vertically therefore no. of rows will remain same and no. of columns will get halved\n",
    "    \n",
    "    #Coverting BGR to HSV\n",
    "    #Reason-HSV format is better suited for object detection as compared to RGB,BGR\n",
    "    hsv=cv2.cvtColor(crop_image,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Capturing the value of trackbar values/Detecting hand\n",
    "    l_h=cv2.getTrackbarPos(\"Lower_H\",\"Colour Adjustments\")\n",
    "    l_s=cv2.getTrackbarPos(\"Lower_S\",\"Colour Adjustments\")\n",
    "    l_v=cv2.getTrackbarPos(\"Lower_V\",\"Colour Adjustments\")\n",
    "    u_h=cv2.getTrackbarPos(\"Upper_H\",\"Colour Adjustments\")\n",
    "    u_s=cv2.getTrackbarPos(\"Upper_S\",\"Colour Adjustments\")\n",
    "    u_v=cv2.getTrackbarPos(\"Upper_V\",\"Colour Adjustments\")\n",
    "    \n",
    "    #creating bounds\n",
    "    lower_bound=np.array([l_h,l_s,l_v])\n",
    "    upper_bound=np.array([u_h,u_s,u_v])\n",
    "    #Any colour will have a darkest pixel value and lightest pixel value , that is why the bounds have been created \n",
    "    \n",
    "    #Creating Mask\n",
    "    mask=cv2.inRange(hsv,lower_bound,upper_bound)\n",
    "    #In the image hsv only show me those pixels whose colour range lie in between lower_bound(darkest pixel) and\n",
    "    #upper_bound(lightest pixel)\n",
    "    \n",
    "    #Filtering mask with image\n",
    "    filtre=cv2.bitwise_and(crop_image,crop_image,mask=mask)\n",
    "    \n",
    "    #inverting the pixels so that the image is white and background is black because this type of setting is ideal in \n",
    "    #detecting the contours\n",
    "    mask1=cv2.bitwise_not(mask)\n",
    "    \n",
    "    #Storing the thresh value in a variable(not compulsory)\n",
    "    m_g=cv2.getTrackbarPos(\"Thresh\",\"Colour Adjustments\")\n",
    "    \n",
    "    #Creating Threshold (Thresholding makes our image easier to analyze during image processing)\n",
    "    ret,thresh=cv2.threshold(mask1,m_g,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    #Performing Dilation for better processing(handling noise)\n",
    "    dilata=cv2.dilate(thresh,(3,3),iterations=6)\n",
    "    \n",
    "    #finding Contours \n",
    "    cnts,hier=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #try and except used for graceful termination of code\n",
    "    try:\n",
    "        #find Contours with maximum area\n",
    "        cm=max(cnts,key=lambda x:cv2.contourArea(x))\n",
    "        \n",
    "        #Contour Approximation\n",
    "        epsilon=0.0005*cv2.arcLength(cm,True)\n",
    "        data=cv2.approxPolyDP(cm,epsilon,True)\n",
    "        hull=cv2.convexHull(cm)\n",
    "        \n",
    "        #Drawing the contours\n",
    "        cv2.drawContours(crop_image,[cm],-1,(50,50,150),2)\n",
    "        cv2.drawContours(crop_image,[hull],-1,(0,255,0),2)\n",
    "        \n",
    "        #Finding Convexity defect (convexity defect is a cavity in an object (blob, contour) segmented out from an image)\n",
    "        #That means an area that do not belong to the object but located inside of its outer boundary \n",
    "        hull=cv2.convexHull(cm,returnPoints=False)\n",
    "        defects=cv2.convexityDefects(cm,hull)\n",
    "        #https://theailearner.com/2020/11/09/convexity-defects-opencv/ (Explaining convexity defects)\n",
    "        count_defects=0\n",
    "        \n",
    "        for i in range(defects.shape[0]):\n",
    "            s,e,f,d=defects[i,0]\n",
    "            start = tuple(cm[s][0])\n",
    "            end = tuple(cm[e][0])\n",
    "            far = tuple(cm[f][0])\n",
    "            \n",
    "            #https://medium.com/analytics-vidhya/hand-detection-and-finger-counting-using-opencv-python-5b594704eb08\n",
    "            #A very good article explaining the math concept perfectly\n",
    "            \n",
    "            #Calculating the length of sides so that we can apply cosine rule\n",
    "            a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "            b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "            c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "            \n",
    "            #Applying cosine rule\n",
    "            angle = (math.acos((b**2 + c**2 - a**2) / (2*b*c))*180) / 3.14\n",
    "            \n",
    "            #Plotting the far points on the basis of angle\n",
    "            if(angle<=50):\n",
    "                count_defects+=1\n",
    "                cv2.circle(crop_image,far,5,(255,255,255),-1)\n",
    "            \n",
    "        if(count_defects==0):\n",
    "            cv2.putText(frame,\" \",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),2)\n",
    "        \n",
    "        elif(count_defects==1):\n",
    "            p.press(\"space\")\n",
    "            cv2.putText(frame,\"Play/Pause\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),2)\n",
    "            \n",
    "        elif(count_defects==2):\n",
    "            p.press(\"up\")\n",
    "            cv2.putText(frame,\"Volume UP\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),2)\n",
    "            \n",
    "        elif(count_defects==3):\n",
    "            p.press(\"down\")\n",
    "            cv2.putText(frame,\"Volume DOWN\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),2)\n",
    "            \n",
    "        elif(count_defects==4):\n",
    "            p.press(\"right\")\n",
    "            cv2.putText(frame,\"Forward\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),2)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Printing the results        \n",
    "    cv2.imshow(\"Result\",frame)\n",
    "    cv2.imshow(\"Thresh\",thresh)\n",
    "    cv2.imshow(\"Filtre\",filtre)\n",
    "    #cv2.imshow(\"mask\",mask)\n",
    "    #cv2.imshow(\"mask1\",mask1)\n",
    "    if(cv2.waitKey(27) & 0xFF==ord('q')):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
